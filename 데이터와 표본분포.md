## 데이터와 표본분포

### 표본분포

- 하나의 동일한 모집단에서 얻은 여러 샘플에 대한 표본통계량의 분포
- 평균과 같은 표본통계량의 분포는 데이터 자체의 분포보다 규칙적이고 종 모양일 가능성이 높음
- 표본이 클수록 표본통계량의 분포가 좁아짐
- 데이터의 값 1000개 표본, 5개 값의 평균 1000개 표본, 20개 값의 평균 1000개 표본을 비교

```r
library(ggplot2)

samp_data <- data.frame(income=sample(loans_income, 1000), type="data_dist")

samp_mean05 <- data.frame(income=tapply(sample(loans_income, 1000 * 5), rep(1:1000, each=5), FUN=mean),
                          type="mean_of_5")

samp_mean20 <- data.frame(income=tapply(sample(loans_income, 1000 * 20), rep(1:1000, each=20), FUN=mean),
                          type="mean_of_20")

income <- rbind(samp_data, samp_mean05, samp_mean20)
income$type <- factor(income$type, levels=c("data_dist", "mean_of_5", "mean_of_20"),
                      labels=c("Data", "Mean of 5", "Mean of 20"))

ggplot(income, aes(x=income)) + geom_histogram(bins=40) + facet_grid(type ~ .)
```

<img src="https://user-images.githubusercontent.com/58063806/131957139-4bed42ac-ae79-42e8-b487-2ffc8d56353f.png" width=75% />

```python
sample_data = pd.DataFrame({"income": [loan_income.sample(1000)], "type": "Data"})

sample_mean_05 = pd.DataFrame({"income": [loan_income.sample(5).mean() for _ in range(1000)], "type": "Mean of 5"})

sample_mean_20 = pd.DataFrame({"income": [loan_income.sample(20).mean() for _ in range(1000)], "type": "Mean of 20"})

results = pd.concat([sample_data, sample_mean_05, sample_mean_20], axis=0)

g = sns.FacetGrid(results, col="type", col_wrap=1, height=2, aspect=4)
g.map(plt.hist, 'income', range=[0, 200000], bins=40)
g.set_axis_labels("Income", "Count")
g.set_titles("{col_name}")
```

<img src="https://user-images.githubusercontent.com/58063806/131957277-a82acd5f-daa3-4d6c-8412-1dfc9762f82c.png" width=75% />

- 평균을 산출하는 샘플의 개수가 많아질수록 히스토그램은 갈수록 좁고 종 모양을 형성

> #### 중심극한정리
>
> 모집단이 정규분포가 아니더라도, 표본크기가 충분하고 데이터가 정규성을 크게 이탈하지 않는 경우, 여러 표본에서 추출한 평균은 종 모양의 정규분포를 형성
>
> #### 표준오차
>
> 표본 측정 지표의 변동성을 측정 (표본통계량의 변동성을 요약)



### 부트스트랩

- 현재 있는 표본에서 추가적으로 표본을 복원추출하고 각 표본에 대한 통계량과 모델을 다시 계산
  - 각 원소가 뽑힐 확률은 그대로 유지하면서 무한한 크기의 모집단을 만들어낼 수 있음
- 부트스트랩 반복 횟수가 많을수록 표준오차나 신뢰구간에 대한 추정이 더 정확해짐

```R
library(boot)

stat_fun <- function(x, idx) median(x[idx])
boot_obj <- boot(loans_income, R=1000, statistic=stat_fun)
boot_obj

# Call:
# boot(data = loans_income, statistic = stat_fun, R = 1000)

# Bootstrap Statistics :
#     original   bias    std. error
# t1*    62000 -71.0395    212.4866
```

```python
from sklearn.utils import resample

results = []
for nrepeat in range(1000):
    sample = resample(loan_income)
    results.append(sample.median())

results = pd.Series(results)
print("Bootstrap Statistics:")
print(f"original: {loan_income.median()}")
print(f"bias: {results.mean() - loan_income.median()}")
print(f"std. error: {results.std()}")

# Bootstrap Statistics:
# original: 62000.0
# bias: -77.27749999999651
# std. error: 220.5330101193522
```

- 중간값의 원래 추정치는 62000으로 부트스트랩의 분포는 추정치에서 bias만큼의 편향이 있고 std. error만큼의 표준오차가 존재



### QQ plot

- 표본이 특정 분포(정규 분포)에 얼마나 가까운지를 시각적으로 판별
- z-score를 오름차순으로 정렬하고 각 값의 z 점수를 y축에 표시, x축은 정규분포에서의 해당 분위수
- 점들이 대각선 위에 놓이면 표본분포가 정규분포에 가까운 것으로 간주

```R
norm_samp <- rnorm(100)
qqnorm(norm_samp)
# a - 절편, b - 기울기
abline(a=0, b=1, col="grey")
```

<img src="https://user-images.githubusercontent.com/58063806/131963377-b58a6993-9769-4e28-af92-28ca30e932eb.png" width=70% />

```python
from scipy import stats
from scipy.stats import probplot

fig, axes = plt.subplots(figsize=(10, 8))
norm_sample = stats.norm.rvs(size=100)
probplot(norm_sample, plot=axes)
axes.set_title("Normal Q-Q plot")
```

<img src="https://user-images.githubusercontent.com/58063806/131964208-2562f895-8495-4187-89f0-8fb4dfdc7105.png" width=70% />

> **원시 데이터 자체는 대게 정규분포가 아니지만 표본들의 평균과 합계 그리고 오차는 대다수 정규분포를 따름**



#### 긴꼬리 분포

- 대칭 및 비대칭 분포 모두 긴 꼬리를 가질 수 있음
  - 꼬리 : 적은 수의 극단값이 주로 존재하는 도수분포의 길고 좁은 부분
  - 왜도 : 분포의 한쪽 꼬리가 반대쪽 다른 꼬리보다 긴 정도

```R
nflx <- sp500_px[, "NFLX"]
nflx <- diff(log(nflx[nflx > 0]))

qqnorm(nflx)
abline(a=0, b=1, col="grey")
```

<img src="https://user-images.githubusercontent.com/58063806/131978906-667779d9-3885-4012-b257-a740c1185839.png" width=70% />

```python
nflx = sp500_px.NFLX
nflx = np.diff(np.log(nflx[nflx > 0]))
fig, axes = plt.subplots(figsize=(10, 8))
probplot(nflx, plot=axes)
axes.set_title("Normal Q-Q plot")
```

<img src="https://user-images.githubusercontent.com/58063806/131979419-2ccb12fc-67ad-4ab0-a01a-914f8e0fe3c4.png" width=70%/>

- 위의 데이터는 정규분포를 따르지 않으며 정규분포를 따른다고 할 때 예상되는 것보다 훨씬 더 많은 극단값을 관찰할 가능성이 있음을 의미



### 이항분포

- 각 시행의 성공 확률(p)가 정해져 있을 때 주어진 시행 횟수(n) 중에서 성공한 횟수(x)의 도수분포를 의미
- 이항분포의 평균은 np, 분산은 np(1 - p)
- 시행 횟수(n)가 크고 p가 0.5에 가까울수록 정규분포로 근사할 수 있음

```R
# n=5인 시행에서 각 시행의 성공확률이 0.1일 때 정확히 2번 성공할 확률
dbinom(x=2, size=5, p=0.1)
# 0.0729

# n=5인 시행에서 각 시행의 성공확률이 0.1일 때 2번 이하 성공할 확률
pbinom(2, 5, 0.1)
# 0.99144
```

```python
# 확률 질량 함수
print(stats.binom.pmf(2, 5, 0.1))
# 0.0729

# 누적 분포 함수 
print(stats.binom.cdf(2, 5, 0.1))
# 0.99144
```



### 카이제곱분포

- 관측 데이터가 특정 분포에 적합한 정도를 나타냄
  - 관찰된 빈도가 기대되는 빈도와 의미있게 다른지 여부를 검정

> 기댓값 - 데이터에서 특이하거나 주목할 만한 것이 없음
>
> (변수 혹은 예측 가능한 패턴 사이에 상관관계가 없음)

- 카이제곱통계량은 **검정 결과가 독립성에 대한 귀무 기댓값에서 벗어난 정도를 측정**하는 통계량

<img src="https://user-images.githubusercontent.com/58063806/132121788-53d4996f-83da-4af0-8f76-bcebdd3f088d.png" width=40% />

[이미지 출처](https://bioinformaticsandme.tistory.com/139)

- 개수 집합에 대해 카이제곱 값이 낮다는 것은 기대 분포를 거의 따르고 있음을 나타내고 카이제곱 값이 높은 것은 기대한 것과 현저하게 다르다는 것을 의미



### F분포

- 측정한 데이터와 관련한 실험 및 선형 모델에 사용됨
- F 통계량은 **각 그룹 내 변동성에 대한 그룹 평균 간 변동성의 비율**을 의미하며 **회귀모형에 의해 설명된 변동성을 데이터 전체의 변동과 비교하기 위해 선형회귀에도 사용**됨



### 푸아송 분포

- 표집된 단위 시간 or 단위 공간에서 발생한 사건의 도수분포
- 핵심 파라미터로 λ(람다)를 가지며 이는 어떤 일정 시간/공간의 구간 내에서 발생한 평균 사건 수를 의미

```R
# λ=2인 푸아송 분포에서 난수 100개를 생성
rpois(100, lambda = 2)
# 0 2 4 0 3 1 1 2 1 ...
```

```python
print(stats.poisson.rvs(2, size=100))
# 3 2 2 3 3 2 1 3 3 ...
```

