## 통계적 실험과 유의성검정

#### 가설검정 (유의성검정)

- **관찰된 효과가 우연에 의한 것인지 여부를 알아내는 것**

### 재표본추출

#### 순열검정

- **두 개 이상의 표본(그룹 A, B ...)**을 함께 결합하여 관측값들을 무작위로 재표본추출하는 과정

1. 여러 그룹의 결과를 단일 데이터 집합으로 결합
2. 결합된 데이터를 섞은 후, 그룹 A와 동일한 크기의 표본을 무작위로(비복원) 추출
3. 나머지 데이터에서 그룹 B와 동일한 크기의 샘플을 무작위로(비복원) 추출
4. 원래 샘플에 대해 구한 통계량 또는 추정치가 무엇이었든 지금 추출한 재표본에 대해 모두 다시 계산 후 기록 **(한번의 순열 반복 진행)**
5. 이전 단계들을 R번 반복하여 검정통계량의 순열분포를 얻음

> 기존에 관찰했던 그룹 간의 차이가 순열 과정에서 얻은 차이의 집합에 들어 있다면, 관찰된 차이는 우연히 일어날 수 있는 범위에 있다고 해석 가능 
>
> 관찰된 차이가 **대부분의 순열분포** 밖에 있다면, 이 차이는 **통계적으로 유의미**하다고 할 수 있음

#### 전체순열검정

- **실제로 나눌 수 있는 모든 가능한 조합**을 찾음
- **샘플 크기가 비교적 작을 때**만 실용적
- 셔플링을 많이 반복할수록, 임의순열검정의 결과는 전체순열검정의 결과와 거의 유사하게 근접
- 좀 더 **정확한 결론을 보장하는 통계적 속성 때문에 정확검정**이라고도 함

#### 부트스트랩 순열검정

1. 여러 그룹의 결과를 단일 데이터 집합으로 결합
2. 결합된 데이터를 섞은 후, 그룹 A와 동일한 크기의 표본을 무작위로(복원) 추출
3. 나머지 데이터에서 그룹 B와 동일한 크기의 샘플을 무작위로(복원) 추출
4. 원래 샘플에 대해 구한 통계량 또는 추정치가 무엇이었든 지금 추출한 재표본에 대해 모두 다시 계산 후 기록 **(한번의 순열 반복 진행)**
5. 이전 단계들을 R번 반복하여 검정통계량의 순열분포를 얻음

- 모집단으로부터 개체선택과정에도 임의성을 보장

#### P-value

- 확률모형이 관측된 결과보다 더 극단적인 결과를 생성하는 빈도
- EX) P-value : 0.3 
  - 우연히 얻은 결과의 30%가 관찰한 것과 비슷한 정도로 예외적인 결과를 얻을 것으로 기대

#### 유의수준

- **랜덤 모델이 주어졌을 때, 그 결과가 관찰된 결과보다 더 극단적일 확률**

> 결과가 통계적으로 유의미하다고해서 실제적으로 유의미하다는 뜻은 아님
>
> 실질적으로 의미 없는 작은 차이라도 표본이 충분히 클 경우 통계적으로 유의하다는 결과가 나올 수 있음

#### 제1종, 2종 오류

- 1종 오류 : 어떤 효과가 우연히 발생한 것인데, 그것이 사실이라고 잘못 판단하는 경우
  - 귀무가설이 사실이지만 기각하고 대립가설을 채택
- 2종 오류 : 어떤 효과가 실제로 있는 것인데, 그것이 우연히 발생한 것이라고 잘못 판단하는 경우
  - 대립가설이 사실이지만 기각하고 귀무가설을 채택

#### t 검정

- 데이터가 수치형인 일반적인 2표본 비교 (A/B 검정)에 주로 사용

```R
t.test(Time ~ Page, data=session_times, alternative="less", var.equal=FALSE)

#	Welch Two Sample t-test

# data:  Time by Page
# t = -1.0983, df = 27.693, p-value = 0.1408
# alternative hypothesis: true difference in means between group Page A and group Page B is less than 0
# 95 percent confidence interval:
#       -Inf 0.1959674
# sample estimates:
# mean in group Page A mean in group Page B 
#             1.263333             1.620000 
```

```python
from scipy import stats

res = stats.ttest_ind(session_times[session_times.Page == "Page A"].Time,
                     session_times[session_times.Page == "Page B"].Time, equal_var=False)
print(f"p-value for single sided test: {res.pvalue / 2:.4f}")

# p-value for single sided test: 0.1408
```

#### 다중검정

- 알파 인플레이션 : 적어도 하나의 예측값이 유의미하다고 검정 결과가 나올 확률
  - EX) 유의수준 0.05, 1 - 0.95<sup>n</sup> 
  - 1종 오류를 만들 확률인 알파가 더 많은 테스트를 수행할수록 증가하는 현상
- 추가하는 변수가 많을수록, 더 많은 모델을 사용할수록 뭔가가 우연에 의해 유의미한 것으로 나타날 확률이 커짐 **(머신러닝 모델이 잡음까지 학습하는 오버피팅과 연관)**

- 통계학의 수정 : 보통 단일 가설검정을 할 때보다 통계적 유의성에 대한 기준을 더 엄격하게 설정
  - 일반적으로 **검정 횟수에 따라 유의수준을 나누는 방법**
  - Bonferroni : 알파를 비교 횟수 n으로 나눔
  - Tukey HSD : 그룹 평균 간의 최대 차이(모든 값을 함께 섞고 원래 그룹과 동일한 크기의 재표본 그룹을 뽑아서 재표본한 그룹 평균 간의 최대 차이)

> #### 데이터를 더 여러 번 사용하고 조작할수록 우연이 더 큰 역할을 할 수 있음

#### 자유도

- 표본 데이터에서 계산된 통계량에 적용, 변화가 가능한 값들의 개수
  - EX) 10개 값으로 이루어진 표본의 평균값을 알고 있으면 9개의 자유도 존재
- 많은 확률분포에 적용되는 자유도 모수는 분포의 모양에 영향을 줌
- 분산과 표준편차에 대한 계산에서 분모의 n - 1이 자유도를 의미
  - n을 사용할 때에 비해 추정값에 대한 편향이 발생하지 않음
- 데이터 크기가 충분히 크면 분모 n과 n - 1의 차이는 거의 없어짐

#### 분산분석 (ANOVA)

- 여러 그룹 간의 통계적으로 유의미한 차이를 검정하는 통계적 절차

**순열검정**

1. 모든 데이터를 하나로 모음
2. 각 집단의 데이터 수에 맞게 재표본 추출
3. 각 그룹의 평균을 구하고 이에 따른 분산을 구함  

```R
library(lmPerm)
df <- read.csv("four_sessions.csv")

summary(aovp(Time ~ Page, data=df))

# [1] "Settings:  unique SS "
# Component 1 :
#             Df R Sum Sq R Mean Sq Iter Pr(Prob)  
# Page1        3    831.4    277.13 3558   0.0964 .
# Residuals   16   1618.4    101.15                
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

```python
import numpy as np
import pandas as pd
import os

df = pd.read_csv(os.path.join(PSDS_PATH, 'four_sessions.csv'), index_col=0)

observed_means = df.pivot_table("Time", index="Page", aggfunc="mean")
observed_variance = observed_means.var()
print(f"Observed means: {observed_means}")
print(f"Variance: {observed_variance}")
# 55.426667

# 각 그룹의 재표본에 대한 평균의 분산 계산 
def perm_test(df):
    df = df.copy()
    df["Time"] = np.random.permutation(df["Time"].values)
    return df.pivot_table("Time", index="Page", aggfunc="mean").var()

# 3000회 반복에 따른 p-value (유의수준 5%에서 )
perm_variance = [perm_test(df) for _ in range(3000)]
print(f"Pr(Prob) {np.mean([var > observed_variance for var in perm_variance])}")
# 0.09166666666666666
```

- Pr(Prob)값 즉, p-value가 0.09 이상이므로 유의수준 5%에서 귀무가설 채택
- 4 집단의 차이가 우연적으로 발생함

**F - 통계량**

- 잔차 오차로 인한 분산과 그룹 평균의 분산에 대한 비율을 기초로 함 
  - 이 비율이 높을수록 통계적으로 유의함

```R
summary(aov(Time ~ Page, data=df))

#             Df Sum Sq Mean Sq F value Pr(>F)  
# Page         3  831.4   277.1    2.74 0.0776 .
# Residuals   16 1618.4   101.2                 
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

```python
import statsmodels.formula.api as smf
import statsmodels.api as sm

model = smf.ols('Time ~ Page', data=df).fit()
aov_table = sm.stats.anova_lm(model)
print(aov_table)

#             df  sum_sq     mean_sq         F    PR(>F)
# Page       3.0   831.4  277.133333  2.739825  0.077586
# Residual  16.0  1618.4  101.150000       NaN       NaN 
```

#### 카이제곱검정

- 횟수 관련 데이터에 주로 사용
- 예상되는 분포에 얼마나 잘 맞는지를 검정
- 일반적으로 변수 간 독립성에 대한 귀무가설이 타당한지를 평가하기 위해 r x c 분할표를 함께 사용
- 각 집단 내 데이터들의 기댓값이 동일하다는 가정이 귀무가설에 속함

> 피어슨 잔차
> $$
> a = 관측값 - 기댓값, b = \sqrt(기댓값)
> \\ R  = \frac a b
> $$
> 카이제곱통계량 - 피어슨 잔차들의 제곱합

- 자유도 : (r - 1) x (c - 1)
  - r : 행, c : 열

1. 모든 데이터를 하나로 모음
2. 각 집단의 데이터 수에 맞게 재표본 추출하고 표본수 계산
3. 이렇게 얻은 횟수와 기대한 회수의 차이를 제곱 합
4. 재표본추출을 통해 얻은 편차의 제곱합이 얼마나 자주 관측값을 초과하는가? (p-value)

```R
chisq.test(clicks, simulate.p.value=TRUE)

# X-squared = 1.6659, df = NA, p-value=0.4853
```

```python
clicks = pd.read_csv(os.path.join(PSDS_PATH, "click_rates.csv"))
clicks = clicks.set_index(["Headline", "Click"]).unstack(level=0)

box = [1] * 34
box.extend([0] * 2966)
random.shuffle(box)


def chi2(observed, expected):
    pearson_residuals = []
    for row, expect in zip(observed, expected):
        pearson_residuals.append([(observe - expect) ** 2 / expect for observe in row])

    return np.sum(pearson_residuals)


expected_clicks = 34 / 3
expected_noclicks = 1000 - expected_clicks
expected = [expected_clicks, expected_noclicks]
print(clicks.values, expected)
chi2observed = chi2(clicks.values, expected)


def perm_fun(box):
    sample_clicks = [sum(random.sample(box, 1000)),
                     sum(random.sample(box, 1000)),
                     sum(random.sample(box, 1000))]
    sample_noclicks = [1000 - n for n in sample_clicks]

    return chi2([sample_clicks, sample_noclicks], expected)


perm_chi2 = [perm_fun(box) for _ in range(2000)]

resampled_p_value = sum(perm_chi2 > chi2observed) / len(perm_chi2)
print(f"Observed chi2: {chi2observed:.4f}")
print(f"Resampled p-value: {resampled_p_value:.4f}")
# Observed chi2: 1.6659
# Resampled p-value: 0.4890
```

- p-value는 재표본추출을 통해 얻은 편차의 제곱합이 얼마나 자주 관측값을 초과하는 것인지를 의미

#### 피셔의 정확검정

- 모든 조합(순열)을 실제로 열거, 빈도를 집계, 관찰된 결과가 얼마나 극단적으로 발생할 수 있는지를 정확하게 결정

```R
fisher.test(df)

# 	Fisher's Exact Test for Count Data

# data:  df
# p-value = 0.4824
# alternative hypothesis: two.sided
```

- p-value 값은 재표본추출 방법을 사용하여 얻은 p 값과 거의 유사함
- 일부 값이 매우 낮고 다른 값이 상대적으로 매우 높은 경우 완전한 정확검정 대신 순열검정을 수행해야 할 수 있음
- simulate.p.value parameter를 이용해 근사 방법을 사용할지 여부를 지정 가능 

> **카이제곱검정이나 피셔의 정확검정은 어떤 효과가 실제인지 아니면 우연인지 알고 싶을 때 사용**  

### 멀티암드 밴딧 (MAB) 알고리즘

- 전통적인 통계적 접근 방식보다 명시적인 최적화와 좀 더 빠른 의사 결정을 가능하게 함

**엡실론-그리디 알고리즘(epsilon-greedy algorithm)**

A/B 검정의 경우

1. 0 ~ 1 사이의 균등분포의 난수를 생성
2. 이 숫자가 0과 **ε(엡실론, 0과 1사이의 값으로 일반적으로 매우 작은 값)** 사이에 존재하면, 50/50 확률로 동전 뒤집기를 시행
   - 동전이 앞면이면 제안 A, 뒷면이면 제안 B를 표시 (랜덤의 의미)
3. 숫자가 ε보다 크면 지금까지 최상의 결과를 보인 제안을 표시

```python
import numpy as np
import random
import matplotlib.pyplot as plt


class EpsilonGreedy:
    def __init__(self, epsilon, counts, values):
        self.epsilon = epsilon
        self.counts = counts
        self.values = values

    def initialize(self, n_arms):
        self.counts = [0 for _ in range(n_arms)]
        self.values = [0.0 for _ in range(n_arms)]

    def ind_max(self, x):
        m = np.argmax(x)
        return m

    # 난수가 epsilon보다 크면 현재 최적의 arm 선택, 작으면 랜덤 선택
    def select_arm(self):
        if random.random() > self.epsilon:
            return self.ind_max(self.values)
        else:
            return random.randrange(len(self.values))

    def update(self, chosen_arm, reward):
        self.counts[chosen_arm] = self.counts[chosen_arm] + 1
        n = self.counts[chosen_arm]
        value = self.values[chosen_arm]
        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward
        self.values[chosen_arm] = new_value

    def test_algorithm(self, arms, num_sims, horizon):
        # (5000, 250)
        chosen_arms = [[0.0 for _ in range(250)] for _ in range(5000)]
        rewards = [[0.0 for _ in range(250)] for _ in range(5000)]
        cumulative_rewards = [[0.0 for _ in range(250)] for _ in range(5000)]

        for sim in range(num_sims):
            self.initialize(len(arms))
            for t in range(horizon):
                # arm 결정
                chosen_arm = self.select_arm()
                chosen_arms[sim][t] = chosen_arm
                reward = arms[chosen_arm].draw()
                rewards[sim][t] = reward
                if t == 0:
                    cumulative_rewards[sim][t] = reward
                else:
                    cumulative_rewards[sim][t] = cumulative_rewards[sim][t - 1] + reward

                self.update(chosen_arm, reward)

        return [chosen_arms, rewards, cumulative_rewards]


class BernoulliArm:
    def __init__(self, p):
        self.p = p

    def draw(self):
        if random.random() > self.p:
            return 0.0
        else:
            return 1.0


random.seed(1)
# 보상
means = [0.1, 0.1, 0.1, 0.1, 0.9]
n_arms = len(means)
random.shuffle(means)
# arm 객체들
arms = list(map(lambda mu: BernoulliArm(mu), means))
print("Best arm is " + str(np.argmax(means)))
best_arm = np.argmax(means)
for epsilon, color in zip([0.1, 0.2, 0.3, 0.4, 0.5], plt.cm.Set1(np.linspace(0, 1, 5))):
    algo = EpsilonGreedy(epsilon, [], [])
    algo.initialize(n_arms)
    results = algo.test_algorithm(arms, 5000, 250)
    for idx, (ax, ylab, title) in enumerate(zip(axes, ["Probability of Selecting Best Arm", "Average Reward", "Cumulative Reward of Chosen Arm"],
                        ["Accuracy of the Epsilon Greedy Algorithm", "Performance of the Epsilon Greedy Algorithm", "Cumulative Reward of Epsilon Greedy Algorithm"])):
        result = results[idx]
        if idx == 0:
            result = result == best_arm
        mean_result = np.mean(result, axis=0)
        ax.plot(range(250), mean_result, label=f"eps={epsilon}", c=color)
        ax.legend()
        ax.set_xlabel("Time", fontsize=15)
        ax.set_ylabel(ylab, fontsize=15)
        ax.set_title(title, fontsize=18)
plt.show()
```

<img src="https://user-images.githubusercontent.com/58063806/142752761-4c5367a8-ab66-4d60-bfbb-4e7d0e79b264.png" width=100% />

- 엡실론-그리디 알고리즘은 epsilon의 값이 어떻든 결국은 어떤 arm이 가장 좋은 것인지 알아낼 수 있음
  - 알고리즘을 얼마나 오래 실행할 것인가, 테스트할 arm이 얼마나 달라지는 것인가에 달려있음
