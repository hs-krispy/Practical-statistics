## 통계적 실험과 유의성검정

#### 가설검정 (유의성검정)

- **관찰된 효과가 우연에 의한 것인지 여부를 알아내는 것**

### 재표본추출

#### 순열검정

- **두 개 이상의 표본(그룹 A, B ...)**을 함께 결합하여 관측값들을 무작위로 재표본추출하는 과정

1. 여러 그룹의 결과를 단일 데이터 집합으로 결합
2. 결합된 데이터를 섞은 후, 그룹 A와 동일한 크기의 표본을 무작위로(비복원) 추출
3. 나머지 데이터에서 그룹 B와 동일한 크기의 샘플을 무작위로(비복원) 추출
4. 원래 샘플에 대해 구한 통계량 또는 추정치가 무엇이었든 지금 추출한 재표본에 대해 모두 다시 계산 후 기록 **(한번의 순열 반복 진행)**
5. 이전 단계들을 R번 반복하여 검정통계량의 순열분포를 얻음

> 기존에 관찰했던 그룹 간의 차이가 순열 과정에서 얻은 차이의 집합에 들어 있다면, 관찰된 차이는 우연히 일어날 수 있는 범위에 있다고 해석 가능 
>
> 관찰된 차이가 **대부분의 순열분포** 밖에 있다면, 이 차이는 **통계적으로 유의미**하다고 할 수 있음

#### 전체순열검정

- **실제로 나눌 수 있는 모든 가능한 조합**을 찾음
- **샘플 크기가 비교적 작을 때**만 실용적
- 셔플링을 많이 반복할수록, 임의순열검정의 결과는 전체순열검정의 결과와 거의 유사하게 근접
- 좀 더 **정확한 결론을 보장하는 통계적 속성 때문에 정확검정**이라고도 함

#### 부트스트랩 순열검정

1. 여러 그룹의 결과를 단일 데이터 집합으로 결합
2. 결합된 데이터를 섞은 후, 그룹 A와 동일한 크기의 표본을 무작위로(복원) 추출
3. 나머지 데이터에서 그룹 B와 동일한 크기의 샘플을 무작위로(복원) 추출
4. 원래 샘플에 대해 구한 통계량 또는 추정치가 무엇이었든 지금 추출한 재표본에 대해 모두 다시 계산 후 기록 **(한번의 순열 반복 진행)**
5. 이전 단계들을 R번 반복하여 검정통계량의 순열분포를 얻음

- 모집단으로부터 개체선택과정에도 임의성을 보장

#### P-value

- 확률모형이 관측된 결과보다 더 극단적인 결과를 생성하는 빈도
- EX) P-value : 0.3 
  - 우연히 얻은 결과의 30%가 관찰한 것과 비슷한 정도로 예외적인 결과를 얻을 것으로 기대

#### 유의수준

- **랜덤 모델이 주어졌을 때, 그 결과가 관찰된 결과보다 더 극단적일 확률**

> 결과가 통계적으로 유의미하다고해서 실제적으로 유의미하다는 뜻은 아님
>
> 실질적으로 의미 없는 작은 차이라도 표본이 충분히 클 경우 통계적으로 유의하다는 결과가 나올 수 있음

#### 제1종, 2종 오류

- 1종 오류 : 어떤 효과가 우연히 발생한 것인데, 그것이 사실이라고 잘못 판단하는 경우
  - 귀무가설이 사실이지만 기각하고 대립가설을 채택
- 2종 오류 : 어떤 효과가 실제로 있는 것인데, 그것이 우연히 발생한 것이라고 잘못 판단하는 경우
  - 대립가설이 사실이지만 기각하고 귀무가설을 채택

#### t 검정

- 데이터가 수치형인 일반적인 2표본 비교 (A/B 검정)에 주로 사용

```R
t.test(Time ~ Page, data=session_times, alternative="less", var.equal=FALSE)

#	Welch Two Sample t-test

# data:  Time by Page
# t = -1.0983, df = 27.693, p-value = 0.1408
# alternative hypothesis: true difference in means between group Page A and group Page B is less than 0
# 95 percent confidence interval:
#       -Inf 0.1959674
# sample estimates:
# mean in group Page A mean in group Page B 
#             1.263333             1.620000 
```

```python
from scipy import stats

res = stats.ttest_ind(session_times[session_times.Page == "Page A"].Time,
                     session_times[session_times.Page == "Page B"].Time, equal_var=False)
print(f"p-value for single sided test: {res.pvalue / 2:.4f}")

# p-value for single sided test: 0.1408
```

#### 다중검정

- 알파 인플레이션 : 적어도 하나의 예측값이 유의미하다고 검정 결과가 나올 확률
  - EX) 유의수준 0.05, 1 - 0.95<sup>n</sup> 
  - 1종 오류를 만들 확률인 알파가 더 많은 테스트를 수행할수록 증가하는 현상
- 추가하는 변수가 많을수록, 더 많은 모델을 사용할수록 뭔가가 우연에 의해 유의미한 것으로 나타날 확률이 커짐 **(머신러닝 모델이 잡음까지 학습하는 오버피팅과 연관)**

- 통계학의 수정 : 보통 단일 가설검정을 할 때보다 통계적 유의성에 대한 기준을 더 엄격하게 설정
  - 일반적으로 **검정 횟수에 따라 유의수준을 나누는 방법**
  - Bonferroni : 알파를 비교 횟수 n으로 나눔
  - Tukey HSD : 그룹 평균 간의 최대 차이(모든 값을 함께 섞고 원래 그룹과 동일한 크기의 재표본 그룹을 뽑아서 재표본한 그룹 평균 간의 최대 차이)

> #### 데이터를 더 여러 번 사용하고 조작할수록 우연이 더 큰 역할을 할 수 있음

